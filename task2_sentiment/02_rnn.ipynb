{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a03ad78",
   "metadata": {},
   "source": [
    "# **Task 2 - Sentiment Classification**\n",
    "\n",
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d31148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>probably alltime favorite movie story selfless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>sure would like see resurrection dated seahunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>show amazing fresh innovative idea 70s first a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>encouraged positive comments film looking forw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>like original gut wrenching laughter like movi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "5  Probably my all-time favorite movie, a story o...  positive   \n",
       "6  I sure would like to see a resurrection of a u...  positive   \n",
       "7  This show was an amazing, fresh & innovative i...  negative   \n",
       "8  Encouraged by the positive comments about this...  negative   \n",
       "9  If you like original gut wrenching laughter yo...  positive   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  one reviewers mentioned watching 1 oz episode ...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically theres family little boy jake thinks...  \n",
       "4  petter matteis love time money visually stunni...  \n",
       "5  probably alltime favorite movie story selfless...  \n",
       "6  sure would like see resurrection dated seahunt...  \n",
       "7  show amazing fresh innovative idea 70s first a...  \n",
       "8  encouraged positive comments film looking forw...  \n",
       "9  like original gut wrenching laughter like movi...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/IMDMovieReview_processed.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab88cc7",
   "metadata": {},
   "source": [
    "Since the dataset is already preprocessed, we just can train directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0704b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1005a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(df['preprocessed'].values)\n",
    "labels = list(df['sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d5b216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic tokenizer\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "# Build vocab\n",
    "all_tokens = [token for text in texts for token in tokenize(text)]\n",
    "vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "vocab.update({word: idx + 2 for idx, (word, _) in enumerate(Counter(all_tokens).items())})\n",
    "\n",
    "# Encode tokens\n",
    "def encode(text):\n",
    "    return [vocab.get(token, vocab['<UNK>']) for token in tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f867bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)  # 'positive'->1, 'negative'->0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "651b57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encoded_texts = [torch.tensor(encode(text), dtype=torch.long) for text in texts]\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded_texts[idx], self.labels[idx]\n",
    "\n",
    "# Collate function to pad batches\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    lengths = torch.tensor([len(x) for x in texts])\n",
    "    padded_texts = pad_sequence(texts, batch_first=True, padding_value=vocab['<PAD>'])\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return padded_texts, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ece3daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels_encoded, test_size=0.2, random_state=42)\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "test_dataset = TextDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "beb3dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab['<PAD>'])\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.embedding(x)  # [B, T, E]\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        output, hidden = self.rnn(packed)\n",
    "        out = self.fc(hidden.squeeze(0))  # hidden: [1, B, H] → [B, H]\n",
    "        return self.sigmoid(out).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7eab2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleRNNClassifier(vocab_size=len(vocab), embedding_dim=100, hidden_dim=64).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c98ee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6519\n",
      "Epoch 2, Loss: 0.6067\n",
      "Epoch 3, Loss: 0.5208\n",
      "Epoch 4, Loss: 0.4226\n",
      "Epoch 5, Loss: 0.3685\n"
     ]
    }
   ],
   "source": [
    "TOTAL_EPOCH = 5\n",
    "for epoch in range(TOTAL_EPOCH):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        x, lengths, y = [b.to(device) for b in batch]\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x, lengths)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb1892f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x, lengths, y = [b.to(device) for b in batch]\n",
    "        preds = model(x, lengths)\n",
    "        predicted = (preds > 0.5).float()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1d39d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.79      0.80      4961\n",
      "    positive       0.80      0.80      0.80      5039\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_preds = np.array(all_preds).astype(int)\n",
    "all_labels = np.array(all_labels).astype(int)\n",
    "\n",
    "# Generate report\n",
    "print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
